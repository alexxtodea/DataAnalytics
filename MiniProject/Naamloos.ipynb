{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d990dc6",
   "metadata": {},
   "source": [
    "# UCI SEMICOM dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c98f2e",
   "metadata": {},
   "source": [
    "After doing research about the dataset which can be found in the *word document* I will have put in the same folder as this analysis, I will now start to work on the dataset. I've taken a look into the dataset ( which you can also see in the sample ) and I know I have many columns with numerical variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c81b16c",
   "metadata": {},
   "source": [
    "#### First we import all the important stuff and our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "008e2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "SemiCom = pd.read_csv(\"uci-secom.csv\")\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe2572",
   "metadata": {},
   "source": [
    "#### I will also add a function that makes sure the output is shown on full screen and not in a scrollable block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba1b5450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.OutputArea.prototype._should_scroll = function(lines) {\nreturn false;\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b6e46c",
   "metadata": {},
   "source": [
    "***\n",
    "Here we can check our data really quick.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aee6735c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2008-08-20 01:42:00</td>\n",
       "      <td>2926.40</td>\n",
       "      <td>2421.45</td>\n",
       "      <td>2180.9666</td>\n",
       "      <td>998.4939</td>\n",
       "      <td>1.3990</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.3311</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>1.3899</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.9800</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>29.1606</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>2008-09-23 22:25:00</td>\n",
       "      <td>2935.34</td>\n",
       "      <td>2551.27</td>\n",
       "      <td>2276.4556</td>\n",
       "      <td>2148.5397</td>\n",
       "      <td>1.2317</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.6778</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>1.4132</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4941</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>3.6018</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>67.6124</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>2008-05-10 14:34:00</td>\n",
       "      <td>3023.56</td>\n",
       "      <td>2555.88</td>\n",
       "      <td>2205.2555</td>\n",
       "      <td>1412.7131</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.2556</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>1.5407</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5018</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>2.5350</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>91.4264</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2008-08-30 11:12:00</td>\n",
       "      <td>3042.36</td>\n",
       "      <td>2493.85</td>\n",
       "      <td>2124.8444</td>\n",
       "      <td>1180.2820</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.7978</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>1.3725</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4970</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>2.8703</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>76.6094</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2008-08-22 10:47:00</td>\n",
       "      <td>2965.48</td>\n",
       "      <td>2467.94</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1657.3518</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>1.5611</td>\n",
       "      <td>...</td>\n",
       "      <td>43.1616</td>\n",
       "      <td>0.5008</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>2.1758</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>43.1616</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time        0        1          2          3       4  \\\n",
       "319   2008-08-20 01:42:00  2926.40  2421.45  2180.9666   998.4939  1.3990   \n",
       "1045  2008-09-23 22:25:00  2935.34  2551.27  2276.4556  2148.5397  1.2317   \n",
       "1323  2008-05-10 14:34:00  3023.56  2555.88  2205.2555  1412.7131  0.9785   \n",
       "579   2008-08-30 11:12:00  3042.36  2493.85  2124.8444  1180.2820  0.8465   \n",
       "414   2008-08-22 10:47:00  2965.48  2467.94  2178.6889  1657.3518  1.6603   \n",
       "\n",
       "          5         6       7       8  ...      581     582     583     584  \\\n",
       "319   100.0  106.3311  0.1216  1.3899  ...      NaN  0.5036  0.0150  0.0035   \n",
       "1045  100.0   93.6778  0.1199  1.4132  ...      NaN  0.4941  0.0178  0.0043   \n",
       "1323  100.0   95.2556  0.1216  1.5407  ...      NaN  0.5018  0.0127  0.0034   \n",
       "579   100.0  100.7978  0.1257  1.3725  ...      NaN  0.4970  0.0143  0.0031   \n",
       "414   100.0  100.8022  0.1229  1.5611  ...  43.1616  0.5008  0.0109  0.0029   \n",
       "\n",
       "         585     586     587     588      589  Pass/Fail  \n",
       "319   2.9800  0.0262  0.0076  0.0022  29.1606         -1  \n",
       "1045  3.6018  0.0257  0.0174  0.0060  67.6124         -1  \n",
       "1323  2.5350  0.0230  0.0210  0.0053  91.4264         -1  \n",
       "579   2.8703  0.0182  0.0139  0.0039  76.6094         -1  \n",
       "414   2.1758  0.0433  0.0187  0.0056  43.1616         -1  \n",
       "\n",
       "[5 rows x 592 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SemiCom.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb0a8c7",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2265b3",
   "metadata": {},
   "source": [
    "***\n",
    "Before I can start to work with this dataset i need to clean it. The information from the dataset said we did have missing values so lets start to work on those:\n",
    "\n",
    "* I first want to see what I'm dealing with. So I can decide if i want to remove columns or add values.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aab403a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927664"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check how many rows and columns we have in this dataset\n",
    "totaldata = np.product(SemiCom.shape)\n",
    "totaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52d0acdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41951"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total amount of missimg data\n",
    "missingdata = SemiCom.isnull().sum()\n",
    "totalmissingdata = missingdata.sum()\n",
    "totalmissingdata "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789d19a8",
   "metadata": {},
   "source": [
    "***\n",
    "Now one thing i want to do is check the percentage of the total missing values in this dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97c5662d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.522219251798065"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(totalmissingdata/totaldata) * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8198afe4",
   "metadata": {},
   "source": [
    "***\n",
    "As you can see not much of the data is missing so removing these wont have a big impact since the dataset has very many values. But, it is necessary to have a clean dataset so that our prediction is more accurate. So my plan is to make a threshold of 25%. When a column is missing more then 25% the collumn gets removed.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "183554b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158    1429\n",
       "292    1429\n",
       "293    1429\n",
       "157    1429\n",
       "85     1341\n",
       "492    1341\n",
       "220    1341\n",
       "358    1341\n",
       "517    1018\n",
       "245    1018\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I wanted to check which colums had the most NaN values\n",
    "missingdata.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "706ee78f",
   "metadata": {},
   "source": [
    "***\n",
    "So here we can see all the columns that are above the threshold and need to be removed. My next step is dropping these columns and checking before and after if columns have been removed. I wanted to do this bit with the 'dropna()' function but this drops rows or columns based on missing values. It cannot be used to drop columns that you specify.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2e648f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['72', '73', '85', '109', '110', '111', '112', '157', '158', '220',\n",
      "       '244', '245', '246', '247', '292', '293', '345', '346', '358', '382',\n",
      "       '383', '384', '385', '492', '516', '517', '518', '519', '546', '547',\n",
      "       '548', '549', '550', '551', '552', '553', '554', '555', '556', '557',\n",
      "       '562', '563', '564', '565', '566', '567', '568', '569', '578', '579',\n",
      "       '580', '581'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.15\n",
    "\n",
    "columns_to_drop = missingdata[missingdata > threshold * len(SemiCom)].index\n",
    "print(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d91722be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
      "       ...\n",
      "       '581', '582', '583', '584', '585', '586', '587', '588', '589',\n",
      "       'Pass/Fail'],\n",
      "      dtype='object', length=592)\n"
     ]
    }
   ],
   "source": [
    "print(SemiCom.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47704a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
      "       ...\n",
      "       '577', '582', '583', '584', '585', '586', '587', '588', '589',\n",
      "       'Pass/Fail'],\n",
      "      dtype='object', length=540)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SemiCom_dropped = SemiCom.drop(columns=columns_to_drop)\n",
    "\n",
    "print(SemiCom_dropped.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a2e4aba",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "As you can see our columns length has gone down from 592 to 540. Now we need look for other ways to remove columns that are useless because now we still have too many columns. \n",
    "After doing some research and asking ChatGPT how i could clean a dataset that has many numerical columns. I found the Variance threshold which means that you remove the columns that have mostly the same information. And because it's almost constantly the same it is not very usefull.\n",
    "\n",
    "This is usefull for me because my dataset has many columns with probably the same information. Which wont provide any extra information for the model.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#had a small error about the time not being able to covert to float\n",
    "SemiCom_dropped['Time'] = pd.to_numeric(SemiCom_dropped['Time'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75910ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time         float64\n",
      "0            float64\n",
      "1            float64\n",
      "2            float64\n",
      "3            float64\n",
      "              ...   \n",
      "586          float64\n",
      "587          float64\n",
      "588          float64\n",
      "589          float64\n",
      "Pass/Fail      int64\n",
      "Length: 540, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(SemiCom_dropped.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ead622dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/opt/anaconda3/envs/DataAnalytics/lib/python3.9/site-packages/sklearn/feature_selection/_variance_threshold.py:104: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  self.variances_ = np.nanvar(X, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '6', '12', '14', '15', '16',\n",
       "       ...\n",
       "       '570', '571', '572', '573', '574', '576', '577', '585', '589',\n",
       "       'Pass/Fail'],\n",
       "      dtype='object', length=251)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "thresholder = VarianceThreshold(threshold=0.05)\n",
    "\n",
    "X_high_variance = thresholder.fit_transform(SemiCom_dropped)\n",
    "#put the remaining columns in a list\n",
    "selected_features = SemiCom_dropped.columns[thresholder.get_support()].tolist()\n",
    "SemiCom_filtered = SemiCom_dropped[selected_features]\n",
    "\n",
    "SemiCom_filtered.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "408df688",
   "metadata": {},
   "source": [
    "***\n",
    "Yep! that was a good one. We just cut our columns in half from 540 to 251.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ad95a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567\n"
     ]
    }
   ],
   "source": [
    "SemiCom_filled = SemiCom_dropped.fillna(SemiCom_dropped.mean())\n",
    "missingdata = SemiCom_filled.isnull().sum()\n",
    "totalmissingdata = missingdata.sum()\n",
    "print(totalmissingdata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2cf816009f15afbcb31a5581dd5e2ba87864b922c5f09b57520046109187d7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
