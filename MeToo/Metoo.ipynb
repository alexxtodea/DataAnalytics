{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "mt = pd.read_csv('MeTooHate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.OutputArea.prototype._should_scroll = function(lines) {\nreturn false;\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "return false;\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Me Too Hate Comments\n",
    "***\n",
    "\n",
    "The goal of this project is to seperate hateful and non-hateful tweets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Cleaning the dataset\n",
    "\n",
    "which we always do by first taking a look at the big picture:\n",
    "- small view of the dataset\n",
    "- check the size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1046207313588236290</td>\n",
       "      <td>Entitled, obnoxious, defensive, lying weasel. ...</td>\n",
       "      <td>2018-09-30T01:17:15Z</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>McAllen, TX</td>\n",
       "      <td>2253</td>\n",
       "      <td>2303</td>\n",
       "      <td>23856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046207328113086464</td>\n",
       "      <td>Thank you  and  for what you did for the women...</td>\n",
       "      <td>2018-09-30T01:17:19Z</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>2559</td>\n",
       "      <td>4989</td>\n",
       "      <td>19889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046207329589493760</td>\n",
       "      <td>Knitting (s) &amp;amp; getting ready for January 1...</td>\n",
       "      <td>2018-09-30T01:17:19Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>St Cloud, MN</td>\n",
       "      <td>16</td>\n",
       "      <td>300</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046207341283168256</td>\n",
       "      <td>Yep just like triffeling women weaponized thei...</td>\n",
       "      <td>2018-09-30T01:17:22Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>flyover country</td>\n",
       "      <td>3573</td>\n",
       "      <td>3732</td>\n",
       "      <td>38361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1046207347016826880</td>\n",
       "      <td>No, the President wants to end  movement posin...</td>\n",
       "      <td>2018-09-30T01:17:23Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>World</td>\n",
       "      <td>294</td>\n",
       "      <td>312</td>\n",
       "      <td>7635</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id                                               text  \\\n",
       "0  1046207313588236290  Entitled, obnoxious, defensive, lying weasel. ...   \n",
       "1  1046207328113086464  Thank you  and  for what you did for the women...   \n",
       "2  1046207329589493760  Knitting (s) &amp; getting ready for January 1...   \n",
       "3  1046207341283168256  Yep just like triffeling women weaponized thei...   \n",
       "4  1046207347016826880  No, the President wants to end  movement posin...   \n",
       "\n",
       "             created_at  favorite_count  retweet_count         location  \\\n",
       "0  2018-09-30T01:17:15Z               5              1      McAllen, TX   \n",
       "1  2018-09-30T01:17:19Z               5              2        Tampa, FL   \n",
       "2  2018-09-30T01:17:19Z               0              0     St Cloud, MN   \n",
       "3  2018-09-30T01:17:22Z               1              0  flyover country   \n",
       "4  2018-09-30T01:17:23Z               0              0            World   \n",
       "\n",
       "   followers_count  friends_count  statuses_count  category  \n",
       "0             2253           2303           23856         0  \n",
       "1             2559           4989           19889         0  \n",
       "2               16            300               9         0  \n",
       "3             3573           3732           38361         1  \n",
       "4              294            312            7635         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(807174, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now we've seen what the data is about and that we have a big dataset to work with.\n",
    "***\n",
    "Next step is looking voor missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status_id               0\n",
      "text                 3536\n",
      "created_at              0\n",
      "favorite_count          0\n",
      "retweet_count           0\n",
      "location           190768\n",
      "followers_count         0\n",
      "friends_count           0\n",
      "statuses_count          0\n",
      "category                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "IsNull = mt.isnull().sum()\n",
    "print(IsNull)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My plan cleaning:\n",
    "We'll remove some of the useless columns first to get rid of useless information, \"Location\" is also going to be removed because it has too many missing values and is also not usefull for finding hate and non-hate comments. Next, we remove the isnull rows from the \"text\" because these are also not usefull for our model. Without any input those rows cannot help predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove useless columns\n",
    "mt = mt.drop(['status_id','location', 'created_at',\n",
    "        'followers_count', 'friends_count', 'statuses_count',\n",
    "       ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(803638, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt = mt.dropna()\n",
    "mt.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that looks a little smaller :)\n",
    "***\n",
    "Next up we use the NLT (Natural Language Toolkit) to clean off punctuation, stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Entitled obnoxious defensive lying weasel This...\n",
       "1         Thank you  and  for what you did for the women...\n",
       "2         Knitting s amp getting ready for January 19 20...\n",
       "3         Yep just like triffeling women weaponized thei...\n",
       "4         No the President wants to end  movement posing...\n",
       "                                ...                        \n",
       "807169    Let’s not forget that this “iconic kiss” was u...\n",
       "807170    DEFINITELYthe only one any of us should suppor...\n",
       "807171    Did the  movement count the dollars of Erin An...\n",
       "807172    This is one of my all time fav songs amp video...\n",
       "807173     I watched your news on the death of the sailo...\n",
       "Name: text_without_punct, Length: 803638, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "#removing punctuations\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text_without_punct = text.translate(translator)\n",
    "    return text_without_punct\n",
    "\n",
    "mt['text_without_punct'] = mt['text'].apply(remove_punctuation)\n",
    "mt['text_without_punct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Entitled obnoxious defensive lying weasel thin...\n",
       "1                                Thank women survivors week\n",
       "2                Knitting amp getting ready January 19 2019\n",
       "3         Yep like triffeling women weaponized poon Wond...\n",
       "4              President wants end movement posing movement\n",
       "                                ...                        \n",
       "807169    Let ’ forget “ iconic kiss ” uninvited sexual ...\n",
       "807170    DEFINITELYthe one us support unconditionally G...\n",
       "807171        movement count dollars Erin Andrews wondering\n",
       "807172    one time fav songs amp videos brutally honest ...\n",
       "807173    watched news death sailor famous WW2 Kiss phot...\n",
       "Name: text_without_stopwords, Length: 803638, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    text_without_stopwords = ' '.join(filtered_tokens)\n",
    "    return text_without_stopwords\n",
    "\n",
    "mt['text_without_stopwords'] = mt['text_without_punct'].apply(remove_stopwords)\n",
    "mt['text_without_stopwords'] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
